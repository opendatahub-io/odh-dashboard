apiVersion: perses.dev/v1alpha1
kind: PersesDashboard
metadata:
  name: dashboard-1-model
spec:
  display:
    name: Models
  duration: 1h
  # Namespace variable - queries Prometheus by default, but can be overridden by NamespaceVariablesProvider
  variables:
    - kind: ListVariable
      spec:
        name: namespace
        display:
          name: Project
          description: Filter by project
        allowMultiple: true
        allowAllValue: true
        customAllValue: ".*"
        defaultValue: "$__all"
        plugin:
          kind: PrometheusLabelValuesVariable
          spec:
            datasource:
              kind: PrometheusDatasource
            labelName: namespace
            matchers:
              - kserve_vllm:num_requests_running
    - kind: ListVariable
      spec:
        name: model_name
        display:
          name: Model deployment
          description: Filter by model deployment
        allowMultiple: true
        allowAllValue: true
        customAllValue: ".*"
        defaultValue: "$__all"
        plugin:
          kind: PrometheusLabelValuesVariable
          spec:
            datasource:
              kind: PrometheusDatasource
            labelName: model_name
            matchers:
              - kserve_vllm:num_requests_running{namespace=~"$namespace"}
  panels:
    # Model Deployments Table
    modelDeploymentsTable:
      kind: Panel
      spec:
        display:
          name: Model deployments
        plugin:
          kind: Table
          spec:
            density: compact
            pagination: true
            transforms:
              - kind: MergeSeries
                spec: {}
            columnSettings:
              - name: timestamp
                hide: true
              - name: model_name
                header: Model deployment
                enableSorting: true
                sort: desc
              - name: namespace
                header: Project
                enableSorting: true
              - name: "value #1"
                hide: true
              - name: "value #2"
                header: Total requests
                enableSorting: true
                format:
                  unit: decimal
                  decimalPlaces: 0
              - name: "value #3"
                header: P90 E2E request latency
                enableSorting: true
                format:
                  unit: seconds
              - name: "value #4"
                header: Error rate
                enableSorting: true
                format:
                  unit: percent-decimal
              - name: "value #5"
                header: GPU utilization
                enableSorting: true
                format:
                  unit: percent
              - name: "value #6"
                header: CPU utilization
                enableSorting: true
                format:
                  unit: percent-decimal
        queries:
          # Query 1: Base model list from vLLM metrics (value hidden, just provides the rows)
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  query: group by (model_name, namespace) (kserve_vllm:num_requests_running{namespace=~"$namespace", model_name=~"$model_name"})
          # Query 2: Total requests - defaults to 0
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  query: sum by (model_name, namespace) (increase(kserve_vllm:request_success_total{namespace=~"$namespace", model_name=~"$model_name"}[$__range])) or (0 * group by (model_name, namespace)(kserve_vllm:num_requests_running{namespace=~"$namespace", model_name=~"$model_name"}))
          # Query 3: P90 E2E request latency - defaults to 0 (filter NaN with > -Inf)
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  query: avg_over_time((histogram_quantile(0.90, sum by (le, model_name, namespace) (rate(kserve_vllm:e2e_request_latency_seconds_bucket{namespace=~"$namespace", model_name=~"$model_name"}[$__rate_interval]))) > -Inf)[$__range:]) or (0 * group by (model_name, namespace)(kserve_vllm:num_requests_running{namespace=~"$namespace", model_name=~"$model_name"}))
          # Query 4: Error rate
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  query: (sum by (model_name, namespace)(increase(kserve_vllm:request_success_total{namespace=~"$namespace", finished_reason=~"error|abort", model_name=~"$model_name"}[$__range])) / (sum by (model_name, namespace)(increase(kserve_vllm:request_success_total{namespace=~"$namespace", model_name=~"$model_name"}[$__range])) > 0)) or (0 * group by (model_name, namespace)(kserve_vllm:num_requests_running{namespace=~"$namespace", model_name=~"$model_name"}))
          # Query 5: GPU utilization %
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  query: avg_over_time((sum by (model_name, namespace) (label_replace(label_replace(accelerator_gpu_utilization{exported_namespace=~"$namespace"}, "namespace", "$1", "exported_namespace", "(.*)"), "pod", "$1", "exported_pod", "(.*)") * on(namespace, pod) group_left(model_name)(0 * max by (namespace, pod, model_name)(kserve_vllm:num_requests_running{namespace=~"$namespace", model_name=~"$model_name"}) + 1)) / scalar(count(accelerator_gpu_utilization)))[$__range:]) or (0 * group by (model_name, namespace)(kserve_vllm:num_requests_running{namespace=~"$namespace", model_name=~"$model_name"}))
          # Query 6: CPU utilization %
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  query: avg_over_time((sum by (model_name, namespace) (node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{namespace=~"$namespace"} * on(namespace, pod) group_left(model_name) (0 * group by (model_name, namespace, pod)(kserve_vllm:num_requests_running{namespace=~"$namespace", model_name=~"$model_name"}) + 1)) / scalar(sum(kube_node_status_allocatable{resource="cpu"})))[$__range:]) or (0 * group by (model_name, namespace)(kserve_vllm:num_requests_running{namespace=~"$namespace", model_name=~"$model_name"}))
    # Performance Metrics - Line Charts
    requestQueueLength:
      kind: Panel
      spec:
        display:
          name: Request queue length
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              mode: list
              position: bottom
              values: []
            visual:
              areaOpacity: 0
              connectNulls: false
              display: line
              lineWidth: 1.5
            yAxis:
              format:
                unit: decimal
              min: 0
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  # Number of requests waiting in queue per model
                  query: sum by (model_name, namespace) (kserve_vllm:num_requests_waiting{namespace=~"$namespace", model_name=~"$model_name"})
                  seriesNameFormat: "{{model_name}}"
    replicaCount:
      kind: Panel
      spec:
        display:
          name: Replica count
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              mode: list
              position: bottom
              values: []
            visual:
              areaOpacity: 0
              connectNulls: false
              display: line
              lineWidth: 1.5
            yAxis:
              format:
                unit: decimal
              min: 0
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  # Ready pods per model - count of pods with vLLM metrics
                  query: count by (model_name, namespace) (group by (pod, model_name, namespace) (kserve_vllm:num_requests_running{namespace=~"$namespace", model_name=~"$model_name"}))
                  seriesNameFormat: "{{model_name}}"
    requestLatency:
      kind: Panel
      spec:
        display:
          name: P90 E2E request latency
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              mode: list
              position: bottom
              values: []
            visual:
              areaOpacity: 0
              connectNulls: false
              display: line
              lineWidth: 1.5
            yAxis:
              format:
                unit: seconds
              min: 0
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  # P90 end-to-end request latency
                  query: (histogram_quantile(0.90, sum by (le, model_name, namespace) (rate(kserve_vllm:e2e_request_latency_seconds_bucket{namespace=~"$namespace", model_name=~"$model_name"}[$__rate_interval]))) > -Inf) or (0 * group by (model_name, namespace)(kserve_vllm:num_requests_running{namespace=~"$namespace", model_name=~"$model_name"}))
                  seriesNameFormat: "{{model_name}}"
    timeToFirstToken:
      kind: Panel
      spec:
        display:
          name: P90 Time to first token (TTFT)
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              mode: list
              position: bottom
              values: []
            visual:
              areaOpacity: 0
              connectNulls: false
              display: line
              lineWidth: 1.5
            yAxis:
              format:
                unit: seconds
              min: 0
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  # P90 time to first token
                  query: (histogram_quantile(0.90, sum by (le, model_name, namespace) (rate(kserve_vllm:time_to_first_token_seconds_bucket{namespace=~"$namespace", model_name=~"$model_name"}[$__rate_interval]))) > -Inf) or (0 * group by (model_name, namespace)(kserve_vllm:num_requests_running{namespace=~"$namespace", model_name=~"$model_name"}))
                  seriesNameFormat: "{{model_name}}"
    tokenThroughput:
      kind: Panel
      spec:
        display:
          name: Token throughput (tokens/sec)
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              mode: list
              position: bottom
              values: []
            visual:
              areaOpacity: 0
              connectNulls: false
              display: line
              lineWidth: 1.5
            yAxis:
              format:
                unit: decimal
              min: 0
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  # Token throughput (prompt + generation tokens per second)
                  query: sum by(model_name, namespace) (rate(kserve_vllm:prompt_tokens_total{namespace=~"$namespace", model_name=~"$model_name"}[$__rate_interval]) + rate(kserve_vllm:generation_tokens_total{namespace=~"$namespace", model_name=~"$model_name"}[$__rate_interval]))
                  seriesNameFormat: "{{model_name}}"
    requestSuccessRate:
      kind: Panel
      spec:
        display:
          name: Request success rate (requests/sec)
        plugin:
          kind: TimeSeriesChart
          spec:
            legend:
              mode: list
              position: bottom
              values: []
            visual:
              areaOpacity: 0
              connectNulls: false
              display: line
              lineWidth: 1.5
            yAxis:
              format:
                unit: decimal
              min: 0
        queries:
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  # Request success rate (successful requests per second)
                  query: sum by (model_name, namespace) (rate(kserve_vllm:request_success_total{namespace=~"$namespace", model_name=~"$model_name", finished_reason=~"length|stop"}[$__rate_interval]))
                  seriesNameFormat: "{{model_name}}"
    responseTimeDistribution:
      kind: Panel
      spec:
        display:
          name: Response time distribution
        plugin:
          kind: BarChart
          spec:
            calculation: last
            sort: asc
        queries:
          # Simplified buckets
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  query: (sum(increase(kserve_vllm:e2e_request_latency_seconds_bucket{namespace=~"$namespace", model_name=~"$model_name", le="+Inf"}[$__range]))) - (sum(increase(kserve_vllm:e2e_request_latency_seconds_bucket{namespace=~"$namespace", model_name=~"$model_name", le="30.0"}[$__range])))
                  seriesNameFormat: "Degraded >30s"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  query: (sum(increase(kserve_vllm:e2e_request_latency_seconds_bucket{namespace=~"$namespace", model_name=~"$model_name", le="30.0"}[$__range]))) - (sum(increase(kserve_vllm:e2e_request_latency_seconds_bucket{namespace=~"$namespace", model_name=~"$model_name", le="5.0"}[$__range])))
                  seriesNameFormat: "Slow 5-30s"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  query: (sum(increase(kserve_vllm:e2e_request_latency_seconds_bucket{namespace=~"$namespace", model_name=~"$model_name", le="5.0"}[$__range]))) - (sum(increase(kserve_vllm:e2e_request_latency_seconds_bucket{namespace=~"$namespace", model_name=~"$model_name", le="1.0"}[$__range])))
                  seriesNameFormat: "Acceptable 1-5s"
          - kind: TimeSeriesQuery
            spec:
              plugin:
                kind: PrometheusTimeSeriesQuery
                spec:
                  datasource:
                    kind: PrometheusDatasource
                  query: (sum(increase(kserve_vllm:e2e_request_latency_seconds_bucket{namespace=~"$namespace", model_name=~"$model_name", le="1.0"}[$__range])))
                  seriesNameFormat: "Fast <1s"
  layouts:
    # Model Deployments Table Section
    - kind: Grid
      spec:
        display:
          title: Model deployments
          collapse:
            open: true
        items:
          - x: 0
            'y': 0
            width: 24
            height: 9
            content:
              '$ref': '#/spec/panels/modelDeploymentsTable'
    # Performance Metrics Section
    - kind: Grid
      spec:
        display:
          title: Performance metrics
          collapse:
            open: true
        items:
          - x: 0
            'y': 0
            width: 12
            height: 8
            content:
              '$ref': '#/spec/panels/requestQueueLength'
          - x: 12
            'y': 0
            width: 12
            height: 8
            content:
              '$ref': '#/spec/panels/replicaCount'
          - x: 0
            'y': 8
            width: 12
            height: 8
            content:
              '$ref': '#/spec/panels/requestLatency'
          - x: 12
            'y': 8
            width: 12
            height: 8
            content:
              '$ref': '#/spec/panels/timeToFirstToken'
          - x: 0
            'y': 16
            width: 12
            height: 8
            content:
              '$ref': '#/spec/panels/tokenThroughput'
          - x: 12
            'y': 16
            width: 12
            height: 8
            content:
              '$ref': '#/spec/panels/requestSuccessRate'
          - x: 0
            'y': 24
            width: 24
            height: 8
            content:
              '$ref': '#/spec/panels/responseTimeDistribution'
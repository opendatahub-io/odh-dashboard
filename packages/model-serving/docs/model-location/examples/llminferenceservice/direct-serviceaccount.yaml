# LLMInferenceService with direct ServiceAccount reference (no Connections API)
# User manually created the SA with S3 credentials
apiVersion: serving.kserve.io/v1alpha1
kind: LLMInferenceService
metadata:
  name: llm-direct-sa
  # No opendatahub.io/connections annotation
spec:
  model:
    name: my-model
    uri: s3://my-bucket/models/my-model
  replicas: 1
  router:
    gateway: {}
    route: {}
    scheduler: {}
  template:
    serviceAccountName: my-s3-sa
    containers:
      - name: main

name: E2E Direct Commit PR Tests

on:
  issue_comment:
    types: [created]

permissions:
  contents: read
  pull-requests: write
  issues: write

env:
  NODE_VERSION: 20.x
  DO_NOT_TRACK: 1

jobs:
  check-comment:
    runs-on: ubuntu-latest
    if: ${{ github.event.issue.pull_request && contains(github.event.comment.body, '/run-e2e-tests-gh') }}
    steps:
      - run: echo "E2E tests requested via /run-e2e-tests-gh comment"

  get-test-tags:
    needs: [check-comment]
    runs-on: self-hosted
    outputs:
      test-tags: ${{ steps.set-tags.outputs.test-tags }}
    steps:
      - name: Set default test tags
        id: set-tags
        # TO:DO - update execution tags and simplify for v1
        run: |
          echo "test-tags=[\"@SmokeSet1\",\"@SmokeSet2\",\"@SmokeSet3\"]" >> $GITHUB_OUTPUT

  e2e-tests:
    needs: [get-test-tags]
    runs-on: self-hosted
    strategy:
      fail-fast: false
      matrix:
        test-tag: ${{ fromJson(needs.get-test-tags.outputs.test-tags) }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: refs/pull/${{ github.event.issue.number }}/head

      - name: Cache npm dependencies
        uses: actions/cache@v4
        id: npm-cache
        with:
          path: |
            ~/.cache/Cypress
            **/node_modules
          key: ${{ runner.os }}-${{ env.NODE_VERSION }}-all-modules-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-${{ env.NODE_VERSION }}-all-modules-

      - name: Setup Node.js ${{ env.NODE_VERSION }}
        if: steps.npm-cache.outputs.cache-hit != 'true'
        uses: actions/setup-node@v4.3.0
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install dependencies
        if: steps.npm-cache.outputs.cache-hit != 'true'
        run: npm ci

      - name: Cache turbo build artifacts
        uses: actions/cache@v4
        with:
          path: ${{ github.workspace }}/.turbo
          key: ${{ runner.os }}-${{ env.NODE_VERSION }}-turbo-${{ github.sha }}-e2e
          restore-keys: |
            ${{ runner.os }}-${{ env.NODE_VERSION }}-turbo-

      - name: Cache OpenShift CLI tarball
        uses: actions/cache@v4
        id: oc-cache
        with:
          path: ${{ runner.temp }}/oc.tar.gz
          key: ${{ runner.os }}-oc-tarball-${{ env.OC_VERSION || '4.15.0' }}

      - name: Check and Install OpenShift CLI
        run: |
          echo "üîç Checking if OpenShift CLI (oc) is installed..."

          # Check if oc is already installed
          if command -v oc &> /dev/null; then
            echo "‚úÖ OpenShift CLI (oc) is already installed"
            oc version --client
          else
            echo "‚ùå OpenShift CLI (oc) not found, installing..."
            echo "üì¶ Installing oc CLI for Linux..."

            OC_TARBALL="${{ runner.temp }}/oc.tar.gz"

            # Check if tarball was cached
            if [ -f "$OC_TARBALL" ]; then
              echo "‚úÖ Using cached OpenShift CLI tarball"
            else
              echo "üì• Downloading OpenShift CLI tarball..."
              curl -LO https://mirror.openshift.com/pub/openshift-v4/clients/oc/latest/linux/oc.tar.gz -o "$OC_TARBALL"
            fi

            # Extract and install oc
            echo "üì¶ Extracting OpenShift CLI..."
            tar -xzf "$OC_TARBALL"
            sudo mv oc /usr/local/bin/
            sudo chmod +x /usr/local/bin/oc

            # Verify installation
            echo "‚úÖ OpenShift CLI installed successfully"
            oc version --client
          fi

          # Final verification
          echo "üéØ Final oc version check:"
          oc version --client || echo "‚ö†Ô∏è  Could not determine oc version"

      - name: Install Cypress Dependencies
        run: |
          echo "üîß Installing Cypress system dependencies for Fedora (based on Cypress docs)..."

          # Use the simplified approach from Cypress documentation for Amazon Linux 2023 (Fedora-compatible)
          if [[ "$RUNNER_OS" == "Linux" ]]; then
            echo "üì¶ Installing minimal Cypress dependencies for Linux..."

            # Based on Cypress docs for Amazon Linux 2023 - Fedora compatible
            echo "Installing core dependencies..."
            sudo dnf install -y xorg-x11-server-Xvfb gtk3-devel nss alsa-lib

            # Add the missing ATK packages that Cypress actually needs
            echo "Installing ATK dependencies..."
            sudo dnf install -y atk atk-devel at-spi2-atk

            # Add additional GUI libraries that might be needed
            echo "Installing additional GUI libraries..."
            sudo dnf install -y libgbm libgbm-devel libnotify libnotify-devel

            # Update library cache
            sudo ldconfig

            # Verify installations
            echo "üîç Verifying installations..."
            if command -v Xvfb &> /dev/null; then
              echo "‚úÖ Xvfb installed"
            else
              echo "‚ùå Xvfb missing"
            fi

            if ldconfig -p | grep -q libnss3; then
              echo "‚úÖ NSS libraries installed"
            else
              echo "‚ùå NSS libraries missing"
            fi

            if ldconfig -p | grep -q libatk; then
              echo "‚úÖ ATK libraries installed (fixes libatk-1.0.so.0 error)"
              echo "üìã ATK libraries found:"
              ldconfig -p | grep libatk
            else
              echo "‚ùå ATK libraries missing - checking what we have..."
              sudo dnf list installed | grep -i atk || echo "No ATK packages found"
              find /usr/lib* -name "*libatk*" 2>/dev/null || echo "No ATK libraries found in filesystem"
            fi

            echo "üéØ Cypress dependencies installation completed"
          fi

      - name: Debug available secrets
        run: |
          echo "üîç DEBUG: Checking available secrets..."
          echo "Event name: ${{ github.event_name }}"
          echo "Repository: ${{ github.repository }}"
          echo "Repository owner: ${{ github.repository_owner }}"
          echo "Ref: ${{ github.ref }}"
          echo "Base ref: ${{ github.base_ref }}"
          echo "Head ref: ${{ github.head_ref }}"

          # Check for specific secrets without revealing values
          if [ -n "${{ secrets.GITLAB_TOKEN }}" ]; then
            echo "‚úÖ GITLAB_TOKEN: Available (length: ${#GITLAB_TOKEN})"
          else
            echo "‚ùå GITLAB_TOKEN: Not available or empty"
          fi

          if [ -n "${{ secrets.GITLAB_TEST_VARS_URL }}" ]; then
            echo "‚úÖ GITLAB_TEST_VARS_URL: Available (length: ${#GITLAB_TEST_VARS_URL})"
          else
            echo "‚ùå GITLAB_TEST_VARS_URL: Not available or empty"
          fi

          # Check other potentially relevant secrets
          if [ -n "${{ secrets.OC_SERVER }}" ]; then
            echo "‚úÖ OC_SERVER: Available"
          else
            echo "‚ùå OC_SERVER: Not available"
          fi

          if [ -n "${{ secrets.OCP_CONSOLE_URL }}" ]; then
            echo "‚úÖ OCP_CONSOLE_URL: Available"
          else
            echo "‚ùå OCP_CONSOLE_URL: Not available"
          fi

          if [ -n "${{ secrets.ODH_DASHBOARD_URL }}" ]; then
            echo "‚úÖ ODH_DASHBOARD_URL: Available"
          else
            echo "‚ùå ODH_DASHBOARD_URL: Not available"
          fi

          # List all available secrets (names only)
          echo "üìã Available secrets in this environment:"
          env | grep -E '^[^=]+=' | sed 's/=.*//' | grep -i secret || echo "No SECRET variables found"

      - name: Download test configuration
        run: |
          # Debug: Show what we're working with
          echo "üîß DEBUG: Attempting to download test configuration..."
          echo "GITLAB_TOKEN present: $([ -n "${{ secrets.GITLAB_TOKEN }}" ] && echo 'YES' || echo 'NO')"
          echo "GITLAB_TEST_VARS_URL present: $([ -n "${{ secrets.GITLAB_TEST_VARS_URL }}" ] && echo 'YES' || echo 'NO')"

          # Try to download test-variables.yml from GitLab securely
          if [ -n "${{ secrets.GITLAB_TOKEN }}" ] && [ -n "${{ secrets.GITLAB_TEST_VARS_URL }}" ]; then
            echo "üîÑ Both secrets are available, attempting download..."
            echo "Token length: ${#GITLAB_TOKEN}"
            echo "URL length: ${#GITLAB_TEST_VARS_URL}"

            # Debug: Show first few characters of secrets (safely)
            if [ -n "${{ secrets.GITLAB_TOKEN }}" ]; then
              echo "Token starts with: ${{ secrets.GITLAB_TOKEN }}" | cut -c1-10
            fi
            if [ -n "${{ secrets.GITLAB_TEST_VARS_URL }}" ]; then
              echo "URL starts with: ${{ secrets.GITLAB_TEST_VARS_URL }}" | cut -c1-20
            fi

            # Try with SSL verification disabled (for self-signed certs)
            if curl -f -k -H "Authorization: Bearer ${{ secrets.GITLAB_TOKEN }}" \
                        "${{ secrets.GITLAB_TEST_VARS_URL }}" \
                        -o ${{ github.workspace }}/frontend/src/__tests__/cypress/test-variables.yml; then
              echo "‚úÖ Successfully downloaded test configuration from GitLab"
              ls -la ${{ github.workspace }}/frontend/src/__tests__/cypress/test-variables.yml
            else
              echo "‚ùå Failed to download from GitLab"
              echo "Curl exit code: $?"

              # Try to get more details about the failure
              echo "Trying without -f to see error details..."
              curl -k -H "Authorization: Bearer ${{ secrets.GITLAB_TOKEN }}" \
                  "${{ secrets.GITLAB_TEST_VARS_URL }}" \
                  -o /tmp/test-response 2>&1 || echo "Curl failed with: $?"

              if [ -f /tmp/test-response ]; then
                echo "GitLab API Response:"
                head -10 /tmp/test-response
              fi

              exit 1
            fi
          else
            echo "‚ö†Ô∏è  GitLab secrets not available - cannot download test configuration"
            echo "üí° This workflow requires GITLAB_TOKEN and GITLAB_TEST_VARS_URL secrets to be configured"
            echo "üí° For forked PRs, these secrets need to be available in the upstream repository"
            echo ""
            echo "üîç DEBUG INFO:"
            echo "- Repository: ${{ github.repository }}"
            echo "- Event: ${{ github.event_name }}"
            echo "- Is fork: $([ '${{ github.repository_owner }}' != 'opendatahub-io' ] && echo 'YES' || echo 'NO')"
            echo "- Base repo: ${{ github.base_ref && github.repository || 'N/A' }}"
            echo ""
            echo "üí° POSSIBLE SOLUTIONS:"
            echo "1. Ensure secrets are configured in upstream repo (opendatahub-io/odh-dashboard)"
            "2. For testing, secrets need to be available when PR is merged"
            "3. Check secret names match exactly: GITLAB_TOKEN, GITLAB_TEST_VARS_URL"
            exit 1
          fi

      - name: Login to OpenShift cluster
        run: |
          # For forked PRs, skip OpenShift login since secrets are not available
          if [ -z "${{ secrets.OC_SERVER }}" ]; then
            echo "‚ö†Ô∏è  OpenShift secrets not available (forked PR) - skipping cluster login"
            echo "üí° Tests will run in mock mode or against local test environment"
            exit 0
          fi

          # Read credentials from downloaded test-variables.yml
          TEST_VARS_FILE="${{ github.workspace }}/frontend/src/__tests__/cypress/test-variables.yml"

          # Install yq for proper YAML parsing if not available
          if ! command -v yq &> /dev/null; then
            echo "üì¶ Installing yq for reliable YAML parsing..."
            sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
            sudo chmod +x /usr/local/bin/yq
          fi

          # Extract credentials using proper YAML parsing
          # This preserves spaces, handles quoted values, and doesn't break on complex YAML
          if command -v yq &> /dev/null; then
            echo "‚úÖ Using yq for reliable YAML parsing"
            
            # Extract OC_ADMIN_USER credentials
            OC_USERNAME=$(yq eval '.OCP_ADMIN_USER.USERNAME' "$TEST_VARS_FILE")
            OC_PASSWORD=$(yq eval '.OCP_ADMIN_USER.PASSWORD' "$TEST_VARS_FILE")
            
            # Extract TEST_USER_3 credentials
            TEST_USER_3_AUTH_TYPE=$(yq eval '.TEST_USER_3.AUTH_TYPE' "$TEST_VARS_FILE")
            TEST_USER_3_USERNAME=$(yq eval '.TEST_USER_3.USERNAME' "$TEST_VARS_FILE")
            TEST_USER_3_PASSWORD=$(yq eval '.TEST_USER_3.PASSWORD' "$TEST_VARS_FILE")
            
            # Extract HTPASSWD_CLUSTER_ADMIN_USER credentials
            HTPASSWD_CLUSTER_ADMIN_AUTH_TYPE=$(yq eval '.HTPASSWD_CLUSTER_ADMIN_USER.AUTH_TYPE' "$TEST_VARS_FILE")
            HTPASSWD_CLUSTER_ADMIN_USERNAME=$(yq eval '.HTPASSWD_CLUSTER_ADMIN_USER.USERNAME' "$TEST_VARS_FILE")
            HTPASSWD_CLUSTER_ADMIN_PASSWORD=$(yq eval '.HTPASSWD_CLUSTER_ADMIN_USER.PASSWORD' "$TEST_VARS_FILE")
            
            # Extract LDAP_CONTRIBUTOR_USER credentials
            LDAP_CONTRIBUTOR_AUTH_TYPE=$(yq eval '.LDAP_CONTRIBUTOR_USER.AUTH_TYPE' "$TEST_VARS_FILE")
            LDAP_CONTRIBUTOR_USERNAME=$(yq eval '.LDAP_CONTRIBUTOR_USER.USERNAME' "$TEST_VARS_FILE")
            LDAP_CONTRIBUTOR_PASSWORD=$(yq eval '.LDAP_CONTRIBUTOR_USER.PASSWORD' "$TEST_VARS_FILE")
            
          else
            echo "‚ö†Ô∏è  yq not available, using Python fallback for YAML parsing"
            
            # Python fallback script for reliable YAML parsing
            python3 << EOF
import yaml
import sys
import os

try:
    with open('$TEST_VARS_FILE', 'r') as f:
        data = yaml.safe_load(f)
    
    # Extract and export credentials with proper handling of None values
    def safe_extract(data, *keys):
        value = data
        for key in keys:
            if isinstance(value, dict) and key in value:
                value = value[key]
            else:
                return ""
        return str(value) if value is not None else ""
    
    # Write to shell environment
    with open(os.environ['GITHUB_ENV'], 'a') as env_file:
        # OCP_ADMIN_USER credentials
        env_file.write(f"OC_USERNAME={safe_extract(data, 'OCP_ADMIN_USER', 'USERNAME')}\n")
        env_file.write(f"OC_PASSWORD={safe_extract(data, 'OCP_ADMIN_USER', 'PASSWORD')}\n")
        
        # TEST_USER_3 credentials
        env_file.write(f"TEST_USER_3_AUTH_TYPE={safe_extract(data, 'TEST_USER_3', 'AUTH_TYPE')}\n")
        env_file.write(f"TEST_USER_3_USERNAME={safe_extract(data, 'TEST_USER_3', 'USERNAME')}\n")
        env_file.write(f"TEST_USER_3_PASSWORD={safe_extract(data, 'TEST_USER_3', 'PASSWORD')}\n")
        
        # HTPASSWD_CLUSTER_ADMIN_USER credentials
        env_file.write(f"HTPASSWD_CLUSTER_ADMIN_AUTH_TYPE={safe_extract(data, 'HTPASSWD_CLUSTER_ADMIN_USER', 'AUTH_TYPE')}\n")
        env_file.write(f"HTPASSWD_CLUSTER_ADMIN_USERNAME={safe_extract(data, 'HTPASSWD_CLUSTER_ADMIN_USER', 'USERNAME')}\n")
        env_file.write(f"HTPASSWD_CLUSTER_ADMIN_PASSWORD={safe_extract(data, 'HTPASSWD_CLUSTER_ADMIN_USER', 'PASSWORD')}\n")
        
        # LDAP_CONTRIBUTOR_USER credentials
        env_file.write(f"LDAP_CONTRIBUTOR_AUTH_TYPE={safe_extract(data, 'LDAP_CONTRIBUTOR_USER', 'AUTH_TYPE')}\n")
        env_file.write(f"LDAP_CONTRIBUTOR_USERNAME={safe_extract(data, 'LDAP_CONTRIBUTOR_USER', 'USERNAME')}\n")
        env_file.write(f"LDAP_CONTRIBUTOR_PASSWORD={safe_extract(data, 'LDAP_CONTRIBUTOR_USER', 'PASSWORD')}\n")
        
    print("‚úÖ Successfully parsed YAML and exported credentials")
        
except Exception as e:
    print(f"‚ùå Error parsing YAML: {e}")
    sys.exit(1)
EOF
            
            # Source the variables for immediate use in this step
            source $GITHUB_ENV
          fi

          # Clean up null/empty values (yq returns "null" for missing values)
          [[ "$OC_USERNAME" == "null" ]] && OC_USERNAME=""
          [[ "$OC_PASSWORD" == "null" ]] && OC_PASSWORD=""
          [[ "$TEST_USER_3_AUTH_TYPE" == "null" ]] && TEST_USER_3_AUTH_TYPE=""
          [[ "$TEST_USER_3_USERNAME" == "null" ]] && TEST_USER_3_USERNAME=""
          [[ "$TEST_USER_3_PASSWORD" == "null" ]] && TEST_USER_3_PASSWORD=""
          [[ "$HTPASSWD_CLUSTER_ADMIN_AUTH_TYPE" == "null" ]] && HTPASSWD_CLUSTER_ADMIN_AUTH_TYPE=""
          [[ "$HTPASSWD_CLUSTER_ADMIN_USERNAME" == "null" ]] && HTPASSWD_CLUSTER_ADMIN_USERNAME=""
          [[ "$HTPASSWD_CLUSTER_ADMIN_PASSWORD" == "null" ]] && HTPASSWD_CLUSTER_ADMIN_PASSWORD=""
          [[ "$LDAP_CONTRIBUTOR_AUTH_TYPE" == "null" ]] && LDAP_CONTRIBUTOR_AUTH_TYPE=""
          [[ "$LDAP_CONTRIBUTOR_USERNAME" == "null" ]] && LDAP_CONTRIBUTOR_USERNAME=""
          [[ "$LDAP_CONTRIBUTOR_PASSWORD" == "null" ]] && LDAP_CONTRIBUTOR_PASSWORD=""

          # Mask sensitive data in logs
          echo "::add-mask::$OC_PASSWORD"
          echo "::add-mask::$OC_USERNAME"

          # Mask all credentials in logs (must happen after extraction)
          echo "::add-mask::$TEST_USER_3_USERNAME"
          echo "::add-mask::$TEST_USER_3_PASSWORD"
          echo "::add-mask::$HTPASSWD_CLUSTER_ADMIN_USERNAME"
          echo "::add-mask::$HTPASSWD_CLUSTER_ADMIN_PASSWORD"
          echo "::add-mask::$LDAP_CONTRIBUTOR_USERNAME"
          echo "::add-mask::$LDAP_CONTRIBUTOR_PASSWORD"

          # Export all credentials as environment variables for Cypress
          echo "TEST_USER_3_AUTH_TYPE=$TEST_USER_3_AUTH_TYPE" >> $GITHUB_ENV
          echo "TEST_USER_3_USERNAME=$TEST_USER_3_USERNAME" >> $GITHUB_ENV
          echo "TEST_USER_3_PASSWORD=$TEST_USER_3_PASSWORD" >> $GITHUB_ENV
          
          # Safely construct JSON objects using jq to prevent shell expansion issues
          # Export variables for jq to access them without shell interpolation
          export HTPASSWD_CLUSTER_ADMIN_AUTH_TYPE HTPASSWD_CLUSTER_ADMIN_USERNAME HTPASSWD_CLUSTER_ADMIN_PASSWORD
          export LDAP_CONTRIBUTOR_AUTH_TYPE LDAP_CONTRIBUTOR_USERNAME LDAP_CONTRIBUTOR_PASSWORD
          
          # Build JSON safely using jq with proper escaping
          HTPASSWD_JSON=$(jq -n \
            --arg auth_type "$HTPASSWD_CLUSTER_ADMIN_AUTH_TYPE" \
            --arg username "$HTPASSWD_CLUSTER_ADMIN_USERNAME" \
            --arg password "$HTPASSWD_CLUSTER_ADMIN_PASSWORD" \
            '{"AUTH_TYPE": $auth_type, "USERNAME": $username, "PASSWORD": $password}')
          
          LDAP_JSON=$(jq -n \
            --arg auth_type "$LDAP_CONTRIBUTOR_AUTH_TYPE" \
            --arg username "$LDAP_CONTRIBUTOR_USERNAME" \
            --arg password "$LDAP_CONTRIBUTOR_PASSWORD" \
            '{"AUTH_TYPE": $auth_type, "USERNAME": $username, "PASSWORD": $password}')
          
          # Write safely constructed JSON to environment
          echo "HTPASSWD_CLUSTER_ADMIN_USER=$HTPASSWD_JSON" >> $GITHUB_ENV
          echo "LDAP_CONTRIBUTOR_USER=$LDAP_JSON" >> $GITHUB_ENV
          
          echo "Logging in to OpenShift cluster..."
          oc login -u "$OC_USERNAME" -p "$OC_PASSWORD" --server="${{ secrets.OC_SERVER }}" --insecure-skip-tls-verify

          # Export OpenShift configuration for Cypress tests
          echo "üîß Setting up OpenShift configuration for Cypress tests..."
          export KUBECONFIG="$HOME/.kube/config"
          echo "KUBECONFIG=$KUBECONFIG" >> $GITHUB_ENV

      - name: Set test configuration
        run: |
          # For forked PRs, use default URLs from local test-vars.yml
          if [ -n "${{ secrets.OCP_CONSOLE_URL }}" ]; then
            sed -i.bak "s|OCP_CONSOLE_URL:.*|OCP_CONSOLE_URL: ${{ secrets.OCP_CONSOLE_URL }}|" ${{ github.workspace }}/frontend/src/__tests__/cypress/test-variables.yml
          fi
          if [ -n "${{ secrets.ODH_DASHBOARD_URL }}" ]; then
            sed -i.bak "s|ODH_DASHBOARD_URL:.*|ODH_DASHBOARD_URL: ${{ secrets.ODH_DASHBOARD_URL }}|" ${{ github.workspace }}/frontend/src/__tests__/cypress/test-variables.yml
          fi

          # For forked PRs, set default URLs if secrets are not available
          if [ -z "${{ secrets.OCP_CONSOLE_URL }}" ]; then
            echo "‚ö†Ô∏è  OCP_CONSOLE_URL secret not available (forked PR) - using localhost"
            sed -i.bak "s|OCP_CONSOLE_URL:.*|OCP_CONSOLE_URL: http://localhost:4010|" ${{ github.workspace }}/frontend/src/__tests__/cypress/test-variables.yml
          fi
          if [ -z "${{ secrets.ODH_DASHBOARD_URL }}" ]; then
            echo "‚ö†Ô∏è  ODH_DASHBOARD_URL secret not available (forked PR) - using localhost"
            sed -i.bak "s|ODH_DASHBOARD_URL:.*|ODH_DASHBOARD_URL: http://localhost:4010|" ${{ github.workspace }}/frontend/src/__tests__/cypress/test-variables.yml
          fi

          export CY_TEST_CONFIG="${{ github.workspace }}/frontend/src/__tests__/cypress/test-variables.yml"

      - name: Start Cypress Server
        run: |
          echo "üßπ Cleaning up any existing processes..."
          pkill -f "webpack.*serve" || echo "No webpack processes found"
          pkill -f "node.*4010" || echo "No node processes on port 4010"
          sleep 2
          
          echo "üöÄ Starting webpack dev server with cluster proxy..."
          cd frontend && npm run start:dev:ext &
          
          SERVER_PID=$!
          echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV
          echo "Started webpack dev server with PID: $SERVER_PID"
          
          # Give the server extra time to start in CI
          echo "‚è≥ Giving server 15 seconds to initialize..."
          sleep 15

      - name: Wait for Server Ready
        run: |
          echo "‚è≥ Waiting for localhost:4010 to be ready..."
          # Use HTTP check instead of TCP since server is clearly running
          npx wait-on http://localhost:4010 --timeout 120000
          echo "‚úÖ Server is responding to HTTP!"
          
          # Verify the application actually loads with more details
          echo "üîç Verifying application loads properly..."
          for i in {1..10}; do
            echo "üîÑ Attempt $i/10: Testing application..."
            
            # Check if basic page loads
            if curl -s -f http://localhost:4010/ > /tmp/response.html 2>/dev/null; then
              echo "‚úÖ HTTP 200 response received"
              
              # Check for dashboard content
              if grep -q "Data Science Projects\|ODH\|Open Data Hub\|Dashboard" /tmp/response.html; then
                echo "‚úÖ Found dashboard content!"
                break
              else
                echo "‚ö†Ô∏è  Page loads but no dashboard content yet..."
                echo "üìÑ Response contains: $(head -c 200 /tmp/response.html | tr '\n' ' ')"
              fi
            else
              echo "‚ùå HTTP request failed"
              curl_exit_code=$?
              echo "Curl exit code: $curl_exit_code"
            fi
            
            if [ $i -lt 10 ]; then
              echo "‚è≥ Waiting 8 seconds before retry..."
              sleep 8
            fi
          done
          
          # Final verification with detailed debugging
          echo "üîç Final application verification..."
          if curl -s -f http://localhost:4010/ | grep -q "Data Science Projects\|ODH\|Open Data Hub\|Dashboard"; then
            echo "‚úÖ Server is ready and application is loaded!"
            
            # Test API endpoint
            echo "üîç Testing API endpoint..."
            if curl -s -f http://localhost:4010/api/status > /dev/null; then
              echo "‚úÖ API proxy is working!"
            else
              echo "‚ö†Ô∏è  API endpoint test failed, but frontend is working"
            fi
          else
            echo "‚ùå Application failed to load properly"
            echo ""
            echo "üìä Debugging information:"
            echo "üîÑ Server process status:"
            ps aux | grep -E '(webpack|node.*4010)' | head -5 || echo "No matching processes found"
            
            echo ""
            echo "üåê Network connectivity test:"
            curl -I http://localhost:4010/ 2>&1 || echo "Connection failed"
            
            echo ""
            echo "üìÑ Raw response (first 1000 chars):"
            curl -s http://localhost:4010/ 2>/dev/null | head -c 1000 || echo "Failed to get response"
            
            echo ""
            echo "üîç Looking for webpack output in background..."
            # Check if there are any relevant log files or output
            ls -la /tmp/ | grep -E "(webpack|error|log)" || echo "No relevant temp files found"
            
            exit 1
          fi

      - name: Run E2E Tests
        run: |
          cd frontend

          echo "üß™ Running commit-based E2E tests..."
          echo "Event: ${{ github.event_name }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Commit: ${{ github.sha }}"

          # Run real E2E tests (not mock mode)
          echo "üöÄ Running real E2E tests against live dashboard"

          # Run tests with matrix tag using Jenkins-style command format
          export CY_TEST_CONFIG="${{ github.workspace }}/frontend/src/__tests__/cypress/test-variables.yml"
          export CY_RESULTS_DIR="${{ github.workspace }}/frontend/src/__tests__/cypress/results/${{ matrix.test-tag }}"

          # Ensure OpenShift configuration is available to Cypress process
          if [ -n "$KUBECONFIG" ]; then
            echo "üîß OpenShift configuration available: $KUBECONFIG"
            # Verify oc command works in this context
            oc whoami || echo "‚ö†Ô∏è  oc whoami failed, but continuing with tests"
          else
            echo "‚ö†Ô∏è  No KUBECONFIG set, OpenShift commands may fail"
          fi

          echo "üéØ Running tests with tags: ${{ matrix.test-tag }}"
          echo "üö´ Skipping tags: @Bug,@Maintain,@NonConcurrent"
          echo "üìã Test group: ${{ matrix.test-tag }}"

          # Use Jenkins-style command format for proper tag filtering
          echo "üîÑ Using Chrome browser"

          # Create results directory
          mkdir -p "$CY_RESULTS_DIR"

          # Run tests against port 4010
          BASE_URL=http://localhost:4010 npm run cypress:run:chrome -- --env skipTags="@Bug @Maintain @NonConcurrent",grepTags="${{ matrix.test-tag }}",grepFilterSpecs=true --config video=true,screenshotsFolder="$CY_RESULTS_DIR/screenshots",videosFolder="$CY_RESULTS_DIR/videos"

      - name: Test tag name
        if: ${{ always() }}
        run: |
          TEST_TAG_NAME=$(echo '${{ matrix.test-tag }}' | tr '/' '_' | tr '@' '_')
          echo "TEST_TAG_NAME=$TEST_TAG_NAME" >> $GITHUB_ENV

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-results-${{ matrix.test-tag }}
          path: |
            frontend/src/__tests__/cypress/results/
            frontend/src/__tests__/cypress/videos/
            frontend/src/__tests__/cypress/screenshots/
            frontend/src/__tests__/cypress/coverage/
          retention-days: 7

      - name: Log test completion
        if: always()
        run: |
          echo "üèÅ E2E Test completed!"
          echo "Status: ${{ job.status }}"
          echo "Event: ${{ github.event_name }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Test Tag: ${{ matrix.test-tag }}"
          echo "Commit: ${{ github.sha }}"
          echo "Run ID: ${{ github.run_id }}"
          echo ""
          echo "üìä Test artifacts uploaded to:"
          echo "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

  cleanup-server:
    needs: [e2e-tests]
    runs-on: self-hosted
    if: ${{ always() && needs.e2e-tests.result != 'skipped' }}
    steps:
      - name: Stop Cypress Servers
        run: |
          echo "üõë Stopping webpack dev server..."
          if [ -n "$SERVER_PID" ]; then
            kill $SERVER_PID || echo "Failed to kill SERVER_PID"
          fi
          pkill -f "webpack.*serve" || echo "No webpack processes found"
          pkill -f "node.*4010" || echo "No node processes on port 4010"
          echo "‚úÖ Server cleanup completed"

